from google.colab import drive
drive.mount('/content/drive', force_remount=True)
     
Mounted at /content/drive

import os
import pandas as pd
import matplotlib.pyplot as plt 
from keras.preprocessing.text import Tokenizer
import seaborn as sns
     

# Change to your own directory as given
try:
    os.chdir("/content/drive/MyDrive/BT4222 Project")
    print("Directory changed")
except OSError:
    print("Error: Can't change the Current Working Directory")
     
Directory changed

# Load dataset
cleaned_df = pd.read_csv('Data/suicide_detection_full_cleaned.csv') 
cleaned_df.head()
     
text	class	cleaned_text
0	Ex Wife Threatening SuicideRecently I left my ...	suicide	sex wife threaten suicide recently leave wife ...
1	Am I weird I don't get affected by compliments...	non-suicide	weird not affect compliment come know real lif...
2	Finally 2020 is almost over... So I can never ...	non-suicide	finally hear bad year swear fucking god annoying
3	i need helpjust help me im crying so hard	suicide	need help just help cry hard
4	I’m so lostHello, my name is Adam (16) and I’v...	suicide	lost hello adam struggle year afraid past year...
Remove irrelevant words

# Obtain word frequency 
tokenizer = Tokenizer()
tokenizer.fit_on_texts(cleaned_df['cleaned_text'])
word_freq = pd.DataFrame(tokenizer.word_counts.items(), columns=['word','count']).sort_values(by='count', ascending=False)
     

# Plot bar graph for word frequency 
plt.figure(figsize=(16, 8))
sns.barplot(x='count',y='word',data=word_freq.iloc[:30])
plt.title('Most Frequent Words')
plt.xlabel("Frequency")
plt.ylabel("Word")
plt.show()
     


# Removed anomalous "filler" word 
cleaned_df['cleaned_text'] = cleaned_df['cleaned_text'].str.replace('filler', '')
     
Remove rows that do not contain any words

# Remove rows with text length 0
cleaned_df = cleaned_df[cleaned_df['cleaned_text'].apply(lambda x: len(x.split())!=0)]
cleaned_df.reset_index(drop=True, inplace=True)
cleaned_df.head()
     
text	class	cleaned_text
0	Ex Wife Threatening SuicideRecently I left my ...	suicide	sex wife threaten suicide recently leave wife ...
1	Am I weird I don't get affected by compliments...	non-suicide	weird not affect compliment come know real lif...
2	Finally 2020 is almost over... So I can never ...	non-suicide	finally hear bad year swear fucking god annoying
3	i need helpjust help me im crying so hard	suicide	need help just help cry hard
4	I’m so lostHello, my name is Adam (16) and I’v...	suicide	lost hello adam struggle year afraid past year...
Remove outliers in word count of texts

# Get word count of posts 
posts_len = [len(x.split()) for x in cleaned_df['cleaned_text']]
pd.Series(posts_len).hist(bins=60)
plt.show()
print(pd.Series(posts_len).describe())
     

count    232009.000000
mean         53.143029
std          89.614739
min           1.000000
25%          12.000000
50%          25.000000
75%          62.000000
max        5850.000000
dtype: float64

# Subset dataset to obtain rows with less than or equal to 62 words
cleaned_df = cleaned_df[cleaned_df['cleaned_text'].apply(lambda x: len(x.split())<=62)]
cleaned_df.reset_index(drop=True, inplace=True)
     

# Check dataset 
cleaned_df.head()
     
text	class	cleaned_text
0	Ex Wife Threatening SuicideRecently I left my ...	suicide	sex wife threaten suicide recently leave wife ...
1	Am I weird I don't get affected by compliments...	non-suicide	weird not affect compliment come know real lif...
2	Finally 2020 is almost over... So I can never ...	non-suicide	finally hear bad year swear fucking god annoying
3	i need helpjust help me im crying so hard	suicide	need help just help cry hard
4	It ends tonight.I can’t do it anymore. \nI quit.	suicide	end tonight not anymore quit

# Export cleaned dataset 
cleaned_df.to_csv('/content/drive/MyDrive/BT4222 Project/Data/suicide_detection_final_cleaned.csv', index=False)
     
